{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of your processed file paths\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\sonur\\OneDrive\\Desktop\\Car_Dheko\\Processed_Data\\Bangalore_preprocessed.csv\",\n",
    "    r\"C:\\Users\\sonur\\OneDrive\\Desktop\\Car_Dheko\\Processed_Data\\Bangalore_preprocessed.csv\",\n",
    "    r\"C:\\Users\\sonur\\OneDrive\\Desktop\\Car_Dheko\\Processed_Data\\Delhi_preprocessed.csv\",\n",
    "    r\"C:\\Users\\sonur\\OneDrive\\Desktop\\Car_Dheko\\Processed_Data\\Hyderabad_preprocessed.csv\",\n",
    "    r\"C:\\Users\\sonur\\OneDrive\\Desktop\\Car_Dheko\\Processed_Data\\Jaipur_preprocessed.csv\",\n",
    "    r\"C:\\Users\\sonur\\OneDrive\\Desktop\\Car_Dheko\\Processed_Data\\Kolkata_preprocessed.csv\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold the DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file and read it into a DataFrame\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv(\"merged_car.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types of Columns:\n",
      "City                       object\n",
      "car_links                  object\n",
      "fuel_type                  object\n",
      "body_type                  object\n",
      "kilometers_driven           int64\n",
      "transmission               object\n",
      "owner                      object\n",
      "oem                        object\n",
      "model                      object\n",
      "year                        int64\n",
      "variant                    object\n",
      "price                      object\n",
      "registration_year         float64\n",
      "insurance_validity         object\n",
      "fuel_type_overview         object\n",
      "seats                     float64\n",
      "kms_driven                  int64\n",
      "rto                        object\n",
      "comfort_convenience        object\n",
      "interior_features          object\n",
      "exterior_features          object\n",
      "safety_features            object\n",
      "entertainment_features     object\n",
      "mileage                   float64\n",
      "engine                    float64\n",
      "max_power                  object\n",
      "torque                    float64\n",
      "wheel_size                float64\n",
      "bhp                       float64\n",
      "rpm                       float64\n",
      "consolidated_data          object\n",
      "dtype: object\n",
      "Categorical Columns:  Index(['City', 'car_links', 'fuel_type', 'body_type', 'transmission', 'owner',\n",
      "       'oem', 'model', 'variant', 'price', 'insurance_validity',\n",
      "       'fuel_type_overview', 'kms_driven', 'rto', 'comfort_convenience',\n",
      "       'interior_features', 'exterior_features', 'safety_features',\n",
      "       'entertainment_features', 'max_power', 'consolidated_data'],\n",
      "      dtype='object')\n",
      "Data preprocessing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from scipy import stats\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\sonur\\OneDrive\\Desktop\\Car_Dheko\\Merged_car\\merged_car.csv\")\n",
    "\n",
    "# 1. Handling Missing Values\n",
    "\n",
    "# For numerical columns, use mean imputation\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "\n",
    "# For categorical columns, use mode imputation or create a new category for missing values\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])  # Updated to avoid FutureWarning\n",
    "\n",
    "# 2. Standardising Data Formats\n",
    "\n",
    "# Example: Removing units and commas from 'kms_driven'\n",
    "if 'kms_driven' in df.columns:\n",
    "    df['kms_driven'] = df['kms_driven'].str.replace(' Kms', '', regex=False)  # Remove ' Kms'\n",
    "    df['kms_driven'] = df['kms_driven'].str.replace(',', '', regex=False)   # Remove commas\n",
    "    df['kms_driven'] = pd.to_numeric(df['kms_driven'], errors='coerce')     # Convert to numeric, coerce errors to NaN\n",
    "\n",
    "# Ensure all columns are of the correct data type\n",
    "print(\"Data Types of Columns:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 3. Encoding Categorical Variables\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Categorical Columns: \", categorical_cols)\n",
    "\n",
    "# One-Hot Encoding (for nominal categorical variables)\n",
    "# Identify actual nominal columns and update the list\n",
    "nominal_columns = [col for col in categorical_cols if df[col].nunique() < 10]  # Example criterion\n",
    "df = pd.get_dummies(df, columns=nominal_columns, drop_first=True)\n",
    "\n",
    "# Label Encoding (for ordinal categorical variables)\n",
    "# Identify actual ordinal columns and update the list\n",
    "ordinal_columns = []  # Replace with actual ordinal column names if any\n",
    "for col in ordinal_columns:\n",
    "    if col in df.columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# 4. Normalizing Numerical Features\n",
    "\n",
    "# Choose between Min-Max Scaling or Standard Scaling\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Ensure no NaN values before scaling\n",
    "df[numerical_cols] = df[numerical_cols].fillna(0)  # Fill NaNs with 0 or another appropriate value\n",
    "\n",
    "# Min-Max Scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df[numerical_cols] = min_max_scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Alternatively, you can use Standard Scaling\n",
    "# standard_scaler = StandardScaler()\n",
    "# df[numerical_cols] = standard_scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# 5. Removing Outliers\n",
    "\n",
    "# Using IQR Method\n",
    "for col in numerical_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df[col] >= (Q1 - 1.5 * IQR)) & (df[col] <= (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Alternatively, use Z-Score Method\n",
    "# df = df[(np.abs(stats.zscore(df[numerical_cols])) < 3).all(axis=1)]\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_merged_car.csv', index=False)\n",
    "\n",
    "print(\"Data preprocessing completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
